{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hebbian Resevoir method 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3eMBLQfaYRRIC09jsfHv2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2yqIQ-PJ9fI"
      },
      "source": [
        "import numpy as np\n",
        "import jax.numpy as jnp \n",
        "import jax\n",
        "from jax import grad,jit,vmap\n",
        "import tensorflow as tf #dataloader\n",
        "tf.config.experimental.set_visible_devices([], \"GPU\")\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as py\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C0FYQ2TLg22"
      },
      "source": [
        "def NLL(x,y): #x =data, y= label one hot\n",
        "  return -jnp.log(x[jnp.argmax(y)]) #assuming one hot\n",
        "\n",
        "def resevoir(inputs,mask,res_params,res_bias): \n",
        "  res_params_m=res_params[0]#*mask[0]\n",
        "  res1=jnp.dot(inputs,res_params_m.T) #+ res_bias[0]\n",
        "  #res1=jax.nn.relu(res1)\n",
        "  res2=res1\n",
        "  for i in range(1,len(res_params)):\n",
        "    res_params_m=res_params[i]#*mask[i]\n",
        "    res2=jnp.dot(res2,res_params_m.T) #+ res_bias[0]\n",
        "    res2=jax.nn.relu(res2)\n",
        "  return res1,res2\n",
        "\n",
        "def forward(inputs,mask,res_params,res_bias,params,bias): \n",
        "  \n",
        "  res1,res2=resevoir(inputs,mask,res_params,res_bias)\n",
        "\n",
        "  layer1=jnp.dot(res2,params[0].T) + bias[0] \n",
        "  layer1=jax.nn.relu(layer1) \n",
        "  layer2=jnp.dot(layer1,params[1].T)+bias[1]\n",
        "  layer2=jax.nn.softmax(layer2)\n",
        "  return layer2,res1,res2\n",
        "\n",
        "v_forward=vmap(forward,in_axes=(0,None,None,None,None,None))\n",
        "v_forward=jit(v_forward) \n",
        "\n",
        "def NLL_loss(inputs,target,mask,res_params,res_bias,params,bias): #loss function only accepts one sample at a time, however I will attempt to remedy this by vmap\n",
        "  pred,_,_=forward(inputs,mask,res_params,res_bias,params,bias)\n",
        "  final=NLL(pred,target)\n",
        "  return final\n",
        "\n",
        "\n",
        "#assumes the gradient input has shape [batch_size,layer]\n",
        "def update_weights(params,bias, dparams,dbias ,lr=0.001): \n",
        "  for i in range(len(params)): #iterate through the layer. \n",
        "    params[i]=params[i]-(lr*jnp.sum(dparams[i],axis=0))\n",
        "    bias[i]=bias[i]-(lr*jnp.sum(dbias[i],axis=0))\n",
        "  return params,bias\n",
        "\n",
        "def plasticity(layer,mask,interval=0.1): \n",
        "  layer_sum=jnp.sum(layer,axis=0) \n",
        "  #print(layer_sum.shape)\n",
        "  for i in range(len(layer_sum)): \n",
        "    if layer_sum[i]<=0: \n",
        "      mask[i]=mask[i]-interval\n",
        "      if mask[i][0]<interval: \n",
        "        mask[i]=0\n",
        "    else: \n",
        "      mask[i]=mask[i]+interval\n",
        "      \n",
        "\n",
        "\n",
        "  return mask\n",
        "\n",
        "\n",
        "\n",
        "gradient = grad(NLL_loss,argnums=(5,6))\n",
        "v_gradient=vmap(gradient,in_axes=(0,0,None,None,None,None,None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzKTqNNwDqXk"
      },
      "source": [
        "CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8348vHugDp3i",
        "outputId": "ed0b0df4-3149-433d-c946-780f4aad9dac"
      },
      "source": [
        "(train_data,train_label),(test_data,test_label) =tf.keras.datasets.cifar10.load_data() \n",
        "\n",
        "train_data=train_data.reshape(50000,1024,3)/255.0 \n",
        "test_data=test_data.reshape(10000,1024,3)/255.0 \n",
        "train_data=jnp.mean(train_data,axis=2)\n",
        "test_data=jnp.mean(test_data,axis=2)\n",
        "\n",
        "train_label=to_categorical(train_label) \n",
        "test_label=to_categorical(test_label) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwXkXmxQiEIn"
      },
      "source": [
        "### DMNIST dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkCfZ2rVe-y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da67f72f-f112-4cb3-9323-865ade0bcc34"
      },
      "source": [
        "(train_data,train_label),(test_data,test_label) =tf.keras.datasets.mnist.load_data() \n",
        "train_data=train_data.reshape(60000,784)/255.0 \n",
        "test_data=test_data.reshape(10000,784)/255.0 \n",
        "train_label=to_categorical(train_label) \n",
        "test_label=to_categorical(test_label) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk0Xd61WS5F_"
      },
      "source": [
        "###Second data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGMYa_RS6lq"
      },
      "source": [
        "(train_data_fash,train_label_fash),(test_data_fash,test_label_fash) =tf.keras.datasets.mnist.load_data() \n",
        "train_data_fash=train_data_fash.reshape(60000,784)/255.0 \n",
        "test_data_fash=test_data_fash.reshape(10000,784)/255.0 \n",
        "train_label_fash=to_categorical(train_label_fash) \n",
        "test_label_fash=to_categorical(test_label_fash) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkVvYOJle3B-"
      },
      "source": [
        "np.random.seed(1002)\n",
        "# Parameters\n",
        "res_param=[]\n",
        "res_bias=[]\n",
        "param=[]\n",
        "bias=[]\n",
        "mask=[]\n",
        "\n",
        "\n",
        "res_param.append(np.random.randn(300,784)/100) \n",
        "\n",
        "\n",
        "#res_param.append(np.random.randn(300,300)/100) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "res_bias.append(np.random.randn(300)/100) \n",
        "\n",
        "\n",
        "param.append(np.random.randn(300,300)/100) \n",
        "param.append(np.random.randn(10,300)/100 ) \n",
        "bias.append(np.random.randn(300)/100) \n",
        "bias.append(np.random.randn(10)/100) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DGbLzU9W9nw"
      },
      "source": [
        "param=[]\n",
        "bias=[]\n",
        "param.append(np.random.randn(300,300)/100) \n",
        "param.append(np.random.randn(10,300)/100 ) \n",
        "bias.append(np.random.randn(300)/100) \n",
        "bias.append(np.random.randn(10)/100) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgx3dZX7ielQ",
        "outputId": "b59f53b4-9a2f-48c8-ad77-fbb0a816d8bd"
      },
      "source": [
        "# it seems like the LR has to be very very small 0.001 tends to have better transfer of learning. \n",
        "#Also removed the Relu on the input layer.\n",
        "ctr=0\n",
        "start_time = timeit.default_timer()\n",
        "for epochs in range(1,50): \n",
        "  for samples in range(50):  \n",
        "    dparam,dbias=jit(v_gradient)(train_data[ctr:ctr+1000],train_label[ctr:ctr+1000],mask,res_param,res_bias,param,bias) \n",
        "    #prune resevoir \n",
        "    _,r1,r2=v_forward(train_data[ctr:ctr+1000],mask,res_param,res_bias,param,bias) \n",
        "    param,bias=jit(update_weights)(param,bias,dparam,dbias,lr=0.001) \n",
        "    ctr=ctr+1000\n",
        "    if ctr>40000: \n",
        "      ctr=0\n",
        "    #if epochs<10:\n",
        "      #mask[0]=mask[0]-0.1\n",
        "      #mask[1]=mask[1]-0.1\n",
        "     # print('pruning')\n",
        "      #mask[0]=(plasticity)(r1,mask[0])\n",
        "      #print('pruning')\n",
        "     # 3mask[1]=(plasticity)(r2,mask[1])\n",
        "    \n",
        "                       \n",
        "   \n",
        "  print(NLL_loss(train_data[0],train_label[0],mask,res_param,res_bias,param,bias)) \n",
        "  pred1,_,_=jit(v_forward)(train_data[40000:40100],mask,res_param,res_bias,param,bias)\n",
        "  pred1=jnp.argmax(pred1,axis=1)\n",
        "\n",
        "  target1=jnp.argmax(train_label[40000:40100],axis=1)\n",
        "  print (f'epoch: ', epochs+1)\n",
        "  print(f'Validation Accuracy: ', len(jnp.where(pred1 == target1)[0])/100*100)\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print (f'Total time: ' ,elapsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.305964\n",
            "epoch:  2\n",
            "Validation Accuracy:  45.0\n",
            "2.7935731\n",
            "epoch:  3\n",
            "Validation Accuracy:  45.0\n",
            "2.4027393\n",
            "epoch:  4\n",
            "Validation Accuracy:  55.00000000000001\n",
            "3.042884\n",
            "epoch:  5\n",
            "Validation Accuracy:  56.00000000000001\n",
            "3.82938\n",
            "epoch:  6\n",
            "Validation Accuracy:  54.0\n",
            "4.075954\n",
            "epoch:  7\n",
            "Validation Accuracy:  44.0\n",
            "3.2687657\n",
            "epoch:  8\n",
            "Validation Accuracy:  57.99999999999999\n",
            "3.9132547\n",
            "epoch:  9\n",
            "Validation Accuracy:  59.0\n",
            "3.820639\n",
            "epoch:  10\n",
            "Validation Accuracy:  64.0\n",
            "3.2748387\n",
            "epoch:  11\n",
            "Validation Accuracy:  61.0\n",
            "3.6225832\n",
            "epoch:  12\n",
            "Validation Accuracy:  65.0\n",
            "2.8224645\n",
            "epoch:  13\n",
            "Validation Accuracy:  56.99999999999999\n",
            "3.7518213\n",
            "epoch:  14\n",
            "Validation Accuracy:  61.0\n",
            "3.6586735\n",
            "epoch:  15\n",
            "Validation Accuracy:  63.0\n",
            "3.4210513\n",
            "epoch:  16\n",
            "Validation Accuracy:  65.0\n",
            "4.282209\n",
            "epoch:  17\n",
            "Validation Accuracy:  65.0\n",
            "3.4008708\n",
            "epoch:  18\n",
            "Validation Accuracy:  66.0\n",
            "3.4223416\n",
            "epoch:  19\n",
            "Validation Accuracy:  65.0\n",
            "4.336059\n",
            "epoch:  20\n",
            "Validation Accuracy:  60.0\n",
            "3.6527317\n",
            "epoch:  21\n",
            "Validation Accuracy:  63.0\n",
            "4.4266615\n",
            "epoch:  22\n",
            "Validation Accuracy:  64.0\n",
            "3.75308\n",
            "epoch:  23\n",
            "Validation Accuracy:  67.0\n",
            "3.9215467\n",
            "epoch:  24\n",
            "Validation Accuracy:  66.0\n",
            "3.9156973\n",
            "epoch:  25\n",
            "Validation Accuracy:  64.0\n",
            "3.2969942\n",
            "epoch:  26\n",
            "Validation Accuracy:  64.0\n",
            "3.8317761\n",
            "epoch:  27\n",
            "Validation Accuracy:  66.0\n",
            "3.9119053\n",
            "epoch:  28\n",
            "Validation Accuracy:  68.0\n",
            "4.16221\n",
            "epoch:  29\n",
            "Validation Accuracy:  68.0\n",
            "3.9338613\n",
            "epoch:  30\n",
            "Validation Accuracy:  63.0\n",
            "3.600134\n",
            "epoch:  31\n",
            "Validation Accuracy:  65.0\n",
            "4.0493517\n",
            "epoch:  32\n",
            "Validation Accuracy:  65.0\n",
            "3.808928\n",
            "epoch:  33\n",
            "Validation Accuracy:  72.0\n",
            "4.138505\n",
            "epoch:  34\n",
            "Validation Accuracy:  71.0\n",
            "3.6807258\n",
            "epoch:  35\n",
            "Validation Accuracy:  73.0\n",
            "3.6468127\n",
            "epoch:  36\n",
            "Validation Accuracy:  65.0\n",
            "3.7010825\n",
            "epoch:  37\n",
            "Validation Accuracy:  71.0\n",
            "4.6532745\n",
            "epoch:  38\n",
            "Validation Accuracy:  64.0\n",
            "3.9577417\n",
            "epoch:  39\n",
            "Validation Accuracy:  68.0\n",
            "4.0146194\n",
            "epoch:  40\n",
            "Validation Accuracy:  69.0\n",
            "4.00227\n",
            "epoch:  41\n",
            "Validation Accuracy:  68.0\n",
            "3.6052322\n",
            "epoch:  42\n",
            "Validation Accuracy:  71.0\n",
            "3.977289\n",
            "epoch:  43\n",
            "Validation Accuracy:  69.0\n",
            "4.4241705\n",
            "epoch:  44\n",
            "Validation Accuracy:  64.0\n",
            "3.9405625\n",
            "epoch:  45\n",
            "Validation Accuracy:  70.0\n",
            "3.5472918\n",
            "epoch:  46\n",
            "Validation Accuracy:  66.0\n",
            "4.538647\n",
            "epoch:  47\n",
            "Validation Accuracy:  69.0\n",
            "4.0010595\n",
            "epoch:  48\n",
            "Validation Accuracy:  64.0\n",
            "3.4129746\n",
            "epoch:  49\n",
            "Validation Accuracy:  69.0\n",
            "3.8621721\n",
            "epoch:  50\n",
            "Validation Accuracy:  66.0\n",
            "Total time:  31.556138135000026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUoiNyvJdsEF"
      },
      "source": [
        "#store params \n",
        "param_mnist = param\n",
        "bias_mnist=bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwt2w4nQQ4wH"
      },
      "source": [
        "#pop layer.\n",
        "res_param.append(param[0])\n",
        "res_bias.append(bias[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlYsmGSsOpyA",
        "outputId": "73f7bf71-3357-4a83-8b18-d452c6992ca7"
      },
      "source": [
        "#Test: \n",
        "pred_1,_,_=v_forward(test_data,mask,res_param,res_bias,param,bias)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(test_label,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 68.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNAvPh2kScd_"
      },
      "source": [
        "#Test: \n",
        "pred_1,_,_=v_forward(test_data_fash,mask,res_param[0:3],res_bias[0:3],param_mnist,bias_mnist)\n",
        "pred_1=jnp.argmax(pred_1,axis=1)\n",
        "target_1=jnp.argmax(test_label_fash,axis=1)\n",
        "print(f'Test Accuracy:',len(jnp.where(pred_1 == target_1)[0])/10000 *100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98P3_w4AeCS1",
        "outputId": "44e35a4e-5e8b-4167-fb88-d36bc71eed77"
      },
      "source": [
        "len(res_param)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJxPIwhcjdsT"
      },
      "source": [
        "#For fashion MNIST\n",
        "#30 epochs and 30 epochs %85.32\n",
        "#30 epochs, push, reinitialize 30 epochs. %85.45\n",
        "#30 epochs, push, reinitialize 30 epochs, reinitialize, 30 epochs %85.46\n",
        "#So they both hit aroudn 85% within those epochs range. \n",
        "\n",
        "\n",
        "#Times = first 30 --> 12.24 seconds second 30-->12.57.\n",
        "\n",
        "#Times = first 30 --> 12.01 seconds , second 30-->12.199\n",
        "\n",
        "#Complexity is O(n) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jez_ht9vDEGC"
      },
      "source": [
        "#For CIAFAR-10 \n",
        "#30 epochs and 30 epochs : 40%\n",
        "#30 epochs pop 30 epochs : 38.31%\n",
        "#30 epochs pop 30 eopchs pop 30 epochs : 40.12999%\n",
        "#no change. "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}